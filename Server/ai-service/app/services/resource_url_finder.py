"""
Resource URL Finder Service using DuckDuckGo Search
Finds real URLs for learning resources generated by the AI
Uses the ddgs library directly for better compatibility
"""
from ddgs import DDGS
import asyncio
import logging
import re
from typing import Optional
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)


class ResourceURLFinder:
    """
    Service to find real URLs for learning resources using DuckDuckGo search.
    Uses the ddgs library directly for reliable results.
    """
    
    def __init__(self):
        logger.info("üîé Initializing ResourceURLFinder with DuckDuckGo...")
        self.executor = ThreadPoolExecutor(max_workers=5)  # Parallel searches
        logger.info("‚úÖ ResourceURLFinder initialized")
    
    def _extract_best_url(self, results: list, platform: str) -> Optional[str]:
        """
        Extract the most relevant URL from search results.
        Prioritizes platform-specific URLs.
        """
        if not results:
            return None
        
        platform_lower = platform.lower() if platform else ""
        
        # Platform-specific URL mapping
        platform_domains = {
            "youtube": ["youtube.com", "youtu.be"],
            "medium": ["medium.com"],
            "freecodecamp": ["freecodecamp.org"],
            "dev.to": ["dev.to"],
            "w3schools": ["w3schools.com"],
            "mdn": ["developer.mozilla.org"],
            "geeksforgeeks": ["geeksforgeeks.org"],
            "hackerrank": ["hackerrank.com"],
            "leetcode": ["leetcode.com"],
            "udemy": ["udemy.com"],
            "coursera": ["coursera.org"],
            "github": ["github.com"],
        }
        
        # Try to find platform-specific URL first
        for platform_key, domains in platform_domains.items():
            if platform_key in platform_lower:
                for result in results:
                    url = result.get("href") or result.get("link") or ""
                    if any(domain in url.lower() for domain in domains):
                        return url
        
        # Fallback: find first valid educational URL
        educational_domains = [
            "youtube.com", "youtu.be", "medium.com", "freecodecamp.org",
            "dev.to", "github.com", "w3schools.com", "developer.mozilla.org",
            "stackoverflow.com", "geeksforgeeks.org", "tutorialspoint.com",
            "coursera.org", "udemy.com", "codecademy.com"
        ]
        
        for result in results:
            url = result.get("href") or result.get("link") or ""
            if any(domain in url.lower() for domain in educational_domains):
                return url
        
        # Last resort: return first URL if available
        if results and (results[0].get("href") or results[0].get("link")):
            return results[0].get("href") or results[0].get("link")
        
        return None
    
    def _sync_search(self, query: str, platform: str) -> Optional[str]:
        """Synchronous search wrapper for thread pool execution"""
        try:
            # Create new DDGS instance for each search (thread-safe)
            with DDGS() as ddgs:
                results = list(ddgs.text(query, max_results=5))
                return self._extract_best_url(results, platform)
        except Exception as e:
            logger.warning(f"Search failed for query '{query[:50]}...': {e}")
            return None
    
    async def find_url(
        self, 
        title: str, 
        platform: str, 
        url_hint: str = ""
    ) -> Optional[str]:
        """
        Find a real URL for a learning resource using DuckDuckGo search.
        
        Args:
            title: Resource title
            platform: Platform name (YouTube, Medium, etc.)
            url_hint: Optional search hints
            
        Returns:
            Real URL string or None if not found
        """
        # Build optimized search query
        query_parts = [title]
        
        if platform:
            query_parts.append(platform)
        
        if url_hint and url_hint != title:
            # Only append first few words of url_hint to avoid too long query
            hint_words = url_hint.split()[:3]
            query_parts.extend(hint_words)
        
        query = " ".join(query_parts)
        
        # Run search in thread pool to avoid blocking
        loop = asyncio.get_event_loop()
        try:
            url = await loop.run_in_executor(
                self.executor,
                self._sync_search,
                query,
                platform
            )
            
            if url:
                logger.debug(f"‚úÖ Found URL for '{title[:30]}...': {url[:50]}...")
            else:
                logger.debug(f"‚ùå No URL found for '{title[:30]}...'")
            
            return url
            
        except Exception as e:
            logger.error(f"Error finding URL for '{title}': {e}")
            return None
    
    async def enrich_resources(self, roadmap_data: dict) -> dict:
        """
        Enrich all resources in a roadmap with real URLs.
        
        Args:
            roadmap_data: Complete roadmap dictionary
            
        Returns:
            Roadmap with enriched resources containing real URLs
        """
        if not roadmap_data.get("days"):
            return roadmap_data
        
        logger.info(f"üîé Enriching resources for {len(roadmap_data['days'])} days...")
        
        total_resources = 0
        found_urls = 0
        
        # Collect all search tasks
        search_tasks = []
        resource_refs = []  # Store references to update
        
        for day in roadmap_data["days"]:
            for task in day.get("tasks", []):
                for resource in task.get("resources", []):
                    if isinstance(resource, dict):
                        total_resources += 1
                        # Create search task
                        search_task = self.find_url(
                            title=resource.get("title", ""),
                            platform=resource.get("platform", ""),
                            url_hint=resource.get("url_hint", "")
                        )
                        search_tasks.append(search_task)
                        resource_refs.append(resource)
        
        if not search_tasks:
            logger.info("üì≠ No resources to enrich")
            return roadmap_data
        
        logger.info(f"üîç Searching for URLs for {total_resources} resources...")
        
        # Execute all searches concurrently with rate limiting
        # Process in batches to avoid overwhelming DuckDuckGo
        batch_size = 5  # Smaller batch size for ddgs
        for i in range(0, len(search_tasks), batch_size):
            batch = search_tasks[i:i + batch_size]
            batch_refs = resource_refs[i:i + batch_size]
            
            results = await asyncio.gather(*batch, return_exceptions=True)
            
            for resource, url in zip(batch_refs, results):
                if isinstance(url, str) and url:
                    resource["url"] = url
                    found_urls += 1
                elif isinstance(url, Exception):
                    logger.warning(f"Search exception: {url}")
                    resource["url"] = ""
                else:
                    resource["url"] = ""
            
            # Small delay between batches to be respectful to DuckDuckGo
            if i + batch_size < len(search_tasks):
                await asyncio.sleep(1.0)
        
        logger.info(f"‚úÖ Resource enrichment complete: {found_urls}/{total_resources} URLs found")
        
        return roadmap_data


# Singleton instance
resource_url_finder = ResourceURLFinder()
